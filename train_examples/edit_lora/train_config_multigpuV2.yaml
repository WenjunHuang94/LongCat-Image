# 1.Data setting
data_txt_root: '/storage/v-jinpewang/az_workspace/wenjun/LongCat-Image/merged_final_dataset/final_train_data_info.txt' # 【修改】指向 20000 条的新数据表
resolution: 512
aspect_ratio_type: 'mar_512'
null_text_ratio: 0.1
dataloader_num_workers: 1
train_batch_size: 1               # 保持 A100 的暴力 8 张吞吐
repeats: 1

prompt_template_encode_prefix: "<|im_start|>system\nAs an image editing expert, first analyze the content and attributes of the input image(s). Then, based on the user's editing instructions, clearly and precisely determine how to modify the given image(s), ensuring that only the specified parts are altered and all other aspects remain consistent with the original(s).<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>"
prompt_template_encode_suffix: '<|im_end|>\n<|im_start|>assistant\n'
prompt_template_encode_start_idx: 67
prompt_template_encode_end_idx: 5

# 2. Model setting
text_tokenizer_max_length: 512
pretrained_model_name_or_path: "/storage/v-jinpewang/az_workspace/wenjun/LongCat-Image-Edit" # 【确认】确认这里是你这台机器上基座模型的正确路径
diffusion_pretrain_weight:  null
use_dynamic_shifting: true

# 【至关重要的一步：继承 Stage 1 的认字记忆】
# 请把这里改成你之前跑出来的、表现最好的那个 checkpoing 绝对路径！
resume_from_checkpoint: '/storage/v-jinpewang/az_workspace/wenjun/LongCat-Image/output/checkpoint-2400/'

# 3. Training setting
lora_rank: 64
use_ema: False
ema_rate: 0.999
mixed_precision: 'bf16'

# 【步数与学习率调整】
max_train_steps: 14900
gradient_accumulation_steps: 8
gradient_checkpointing: true
gradient_clip: 1.0
learning_rate: 1.0e-4             # 【下降】降为 1e-4。为了保护 Stage 1 的特征不被破坏，Stage 2 必须温柔一点。
adam_weight_decay: 1.0e-2
adam_epsilon: 1.0e-8
adam_beta1: 0.9
adam_beta2: 0.999
lr_num_cycles: 1
lr_power: 1.0
lr_scheduler: 'constant_with_warmup'
lr_warmup_steps: 500

#4. Log setting
log_interval: 1
save_model_steps: 250
work_dir: 'output/edit_lora_model_stage2_final-20260225'
seed: 43